---
title: Transformer块
description: Transformer块
pubDate: 2025-10-09
toc: true
ogImage: true
category: LLM
---

整个大语言模型就是由一系列 Transformer 块组成的。每个块处理其输入，然后将处理结果传递给下一块。

在原始的 Transformer 论文中约为 6 块，现在许多 LLM 中已经超过 100 个了。

<img
  src="https://xiejie-typora.oss-cn-chengdu.aliyuncs.com/2025-05-27-003618.png"
  alt="image-20250527083618654"
  style="zoom:50%;"
/>

每个 Transformer 块由以下两首首尾相接的组件构成：

1. 自注意力层
2. 前馈神经网络层

<img
  src="https://xiejie-typora.oss-cn-chengdu.aliyuncs.com/2025-05-27-004133.png"
  alt="image-20250527084133186"
  style="zoom:50%;"
/>

## 自注意力层

注意力机制帮助模型在处理特定词元的时候 **整合上下文信息**。

```
狗追猫，因为它
```

为了预测“它”之后的内容，模型需要知道“它”指代的是什么，是“狗”还是“猫” ？

注意力机制会将上下文信息添加到“它”这个词元的表示中。

<img
  src="https://xiejie-typora.oss-cn-chengdu.aliyuncs.com/2025-05-27-012001.png"
  alt="image-20250527092001387"
  style="zoom:50%;"
/>

### 1. 自注意力工作原理

注意力机制会为“它”这个词元计算它与句子中所有其他词元的关联程度。

- 它会算出“它”和“狗”有多相关
- “它”和“猫”有多相关
- 甚至“它”和“追”“因为”等词之间的关系

这些相关性通过一个叫做“注意力权重”的分数来表示，**相关性越高，注意力分数越大**。

下图是另外一段英文提示词文本

```
The cat sat on the mat
```

在自注意力层所生成的权重矩阵图：

<img
  src="https://xiejie-typora.oss-cn-chengdu.aliyuncs.com/2025-05-27-013544.png"
  alt="output"
  style="zoom:36%;"
/>

- 横轴（Key）：表示被关注的词，即“被看的对象”；

- 纵轴（Query）：表示当前在处理的词，即“正在看别人的词”；

- 单元格中的值：表示 Query 对应的词对 Key 的关注程度（注意力权重），数值越大，颜色越深。

图中 `sat → The` 的注意力值是 `0.23`，意味着在处理 “sat” 这个词时，模型“最关注”的词之一是 “The”；`cat → on` 的注意力值是 `0.21`，表示 “cat” 在编码时也部分关注了 “on”。

回到我们上面“狗追猫”的例子，假设注意力机制得出以下权重：

```
"它" 对每个词的注意力权重：
狗：0.3
猫：0.6
其他词：0.1
```

模型“认为”——“它”更可能指的是“猫”。

那么模型可能就会生成诸如“它吓倒了狗”的后续内容。

核心：当前词会去关注其它词，并且根据相关性分配权重，从而形成更有语境感知的一个表达。

### 2. 多头注意力

所谓多头注意力，指的是模型不只使用一个注意力机制去“看”上下文，而是使用多个注意力头（head）**，每个从不同的角度并行地关注输入中的不同部分。**

一个注意力头只关注一套特定的关系（比如“它”和“狗、猫”之间的关系），但现实语言中的语义很复杂：

- 有的头可能专注于语法（主语-动词关系）；
- 有的头可能关注指代（“它”指代谁）；
- 有的头可能关注情感、时间顺序等……

多头注意力可以让模型从多个“子空间”中提取信息，从而提升理解力和泛化能力。

例如：

```
狗追猫，因为它
```

假设有三个注意力头，它们分别学习到了不同的关注模式：

- **Head 1：指代消解视角** —— “它”主要关注“猫”，注意力权重为：猫 0.6，狗 0.3，其它词 0.1；
- **Head 2：句法结构视角** —— “它”关注“追”这个动词，理解句子动作逻辑；在这个头中，“追”的相关性得分最高
- **Head 3：逻辑关系视角** —— “它”关注“因为”，模型试图理解因果结构。在这个头中，“因为”的相关性得分最高

这些注意力头会各自生成一份“它”的表示，最后再把这些表示**合并起来**，形成一个更加丰富、综合的向量。这个向量同时融合了：

- 谁是“它”可能指代的对象，
- “它”参与了什么样的动作，
- “它”在语义上处于怎样的逻辑位置。
- .....

“它”所对应的向量的含义背后的语义就非常丰富了。这也是为什么前面说 LLM 只需要取最后一个词元来预测下一个词。

这就像一个小型“专家团队”，每个注意力头都是一个“专家”，专门从某种语言视角来理解当前词元。最终，它们的意见会被整合，让模型拥有更全面的判断力。

## 前馈神经网络层

自注意力机制让每个词元在上下文中“看别人”，整合其他词的信息。但仅靠这些信息还不够，Transformer 还需要进一步让每个词**自己思考、提炼、变换**。这个任务，就交给了前馈神经网络层（Feed Forward Neural Network，简称 FFN）。

前馈神经网络的特别之处在于：它不会“看别人”，只处理**自己**。

🙋怎么处理？

它是**对每一个词元单独做的一次变换处理**。你可以理解为：自注意力层结束后，每个词元都从“他人”那里学到了不少内容；接下来轮到它自己好好消化一遍。

🙋如何消化？

其实就是把词元当前的表示向量送入一个小型的神经网络中，通常会包含两层线性变换和一个非线性激活函数，流程如下：

```
输入 → 线性变换（升维） → 激活函数 → 线性变换（降维） → 输出
```

再具体一点的话，这一过程可以用公式表示为：

$$
FFN(x)=GELU(xW1+b1)W2+b2
$$

其中 GELU 是一种激活函数，负责加入“非线性思考能力”。

例如：

```
狗追猫，因为它
```

在经过自注意力机制之后，“它”这个词已经看向了上下文，并初步融合了来自“猫”“狗”等词的语义信息。

但是，这样的表示只是“初加工品”。模型还需要进一步处理它，让它具备更强的语义表达能力和推理能力。这时，“它”的向量就会被送入前馈网络中：

- 前馈层会先把这个向量升维到一个更高维度（比如从 768 维扩展到 3072 维）；
- 接着，经过 GELU 激活函数进行非线性处理；
- 然后再降维回原来的大小，形成一个新的、更复杂的向量表示。

这个新表示就是“它”这个词元的升级版本，里面包含了模型对“它”这个词更深层的理解，可以帮助模型提取出更适合判断行为、情感、逻辑的语义特征。最终形成的向量将送入下一层 Transformer，继续处理。

因此，前馈层也是非常重要的一层，看起来只是“对每个词做了一遍变换”，但它非常关键。如果 Transformer 只有注意力层没有前馈层，那它就像是一个只会模仿别人的人，不会自己总结、推理和表达。如果说自注意力阶段是“看外部世界”，那么前馈网络阶段就是“闭上眼睛思考自己”。

---

-EOF-
