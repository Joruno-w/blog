---
title: 大模型幻觉
description: 大模型幻觉
pubDate: 2025-10-09
toc: true
ogImage: true
category: LLM
---

AI hallucination，中文叫做“大模型幻觉”。

指的是大模型生成的内容听起来合理、语法正确，但其实是 **虚构、不准确、错误或编造出来的**。

一本正经的胡说八道。

例如：

> 你问模型：“请告诉我牛顿的母亲发明了什么科学理论？”
>
> 模型可能回答：“牛顿的母亲汉娜·艾斯科夫特发明了地心引力理论。”

大模型幻觉常见例子：

1. “莎士比亚写过《数据科学之路》” - 编造事实
2. “这本书发表于 2021 年清华出版社”，实际上并没有这本书 - 虚构的引用/虚构的文献/错误的时间/错误的信息
3. 把 A 的成果说成 B 的 - 张冠李戴
4. 编造一个不存在的函数 `torch.magic_fit()` - 虚构不存在的 API 或者代码
5. “爱因斯坦曾参加世界杯足球赛” - 虚构的历史/虚构的事件

🤔为什么会出现大模型幻觉？

1. 基于统计学习：你给它相应的语料库，它根据你提供的语料库进行学习
2. 训练数据不完整或有偏差
3. 对人类提问的“补全压力”

🙋如何解决大模型幻觉？

让大模型回答问题更加符合我们的期望。

1. 提示词工程
2. RAG - 外挂知识库
3. 大模型微调

---

-EOF-
