---
title: Transformer解码策略
description: Transformer解码策略
pubDate: 2025-10-09
toc: true
ogImage: true
category: LLM
---

根据概率选择词元的方法被称之为**解码策略（decoding strategy）**。

常见的策略包括：

- 贪婪策略（Greedy）：选最大值
- 采样策略（Top-k, Top-p）：引入随机性，增加多样性

## 贪婪策略

每一步都选择当前 **概率最大** 的词元作为下一个输出，不考虑后续潜在可能性。

例如当前上下文是：“我今天很”，模型输出的 softmax 概率如下：

```
{
  开心: 0.61,
  累: 0.12,
  忙: 0.08,
  美丽: 0.04,
  ...（共 50000 个词）
}
```

如果使用贪婪策略解码，下一词 = 选择概率最大的词 = “开心”

**优点：**

1. 简单易实现
2. 速度快

**缺点：**

1. 缺乏多样性：同样的输入每次都会得到同样的输出
2. 容易陷入局部最优

## 采样策略

采样策略是在每一步生成时，**不总是选概率最大的词**，而是**根据 softmax 概率分布进行随机抽样**，这样每次生成可能都不一样，增强语言多样性。

例如上面的 softmax 输出为：

```
{
  开心: 0.61,
  累: 0.12,
  忙: 0.08,
  美丽: 0.04,
  ...（共 50000 个词）
}
```

那么会根据概率**随机抽一个**：

- 可能是“开心”（61%）
- 也可能是“累”（12%）
- 有小概率是“美丽”（4%）

采样策略的核心思想是：不是总选最有可能的那个词，而是让 **“可能性高的词更有可能被选中”**，但不是唯一结果。

**优点：**

1. 多样性高：同样的输入，可以生成多种不同的合理输出
2. 更自然

**缺点：**

1. 不可控
2. 有时会胡说八道

## 温度系数（Temperature）

在采样策略中，可以引入一个**温度系数（temperature）** 来控制 softmax 概率分布的“陡峭程度”，影响模型的“随机性”与“确定性”。

**原理**

默认 softmax 的计算方式如下：

```js
probs = softmax(logits) // 将分数转为概率
```

加入温度 T 后，变为：

```
probs = softmax(logits / T)
```

其中：

- T 是一个正数（一般取值 0.5 ~ 2）
- logits 除以 T 后，整个分布会变化

**温度的影响**

| 温度 T | 分布特征 | 解码表现           |
| ------ | -------- | ------------------ |
| T < 1  | 更尖锐   | 更偏向高概率词     |
| T = 1  | 原始分布 | 标准采样           |
| T > 1  | 更平坦   | 更倾向随机、多样化 |

**示例说明**

仍以上面的 logits 为例：

```
{
  开心: 4.2,
  累: 2.7,
  忙: 1.5,
  昨天: -1.2,
  小狗: -3.5
}
```

不同温度下的行为：

- T = 1：开心（61%）仍最可能，但其他词有较低概率
- T = 0.5：开心更具压倒性优势（例如 >80%）
- T = 2.0：其他词概率显著提升，分布变“平”

温度越低，越倾向于选择高概率的词，温度越高，越倾向于选择其他词

**最佳实践**

- 想生成“稳定”“一致性强”的结果 → 使用低温度（如 T = 0.7）
- 想生成“有创意”“更多样”的结果 → 使用高温度（如 T = 1.5）

> 总结一句话：温度系数是控制生成文本“保守”还是“放飞”的旋钮。

## 其他解码策略

除了贪婪策略和采样策略，还有一些常用的高级解码方式：

| 策略                 | 每一步做什么                | 效果                      |
| -------------------- | --------------------------- | ------------------------- |
| **贪婪解码**         | 选概率最大                  | 单一、重复、稳定          |
| **采样（随机）**     | 根据概率随机选一个词        | 多样、有趣但不稳定        |
| **Top-k**            | 只在概率前 k 名中随机选     | 控制随机性 + 保留合理选项 |
| **Top-p（nucleus）** | 在累计概率 > p 的词中随机选 | 更智能的采样策略          |
| **Beam Search**      | 保留多个候选句分支并评分    | 更接近全局最优但计算更贵  |

---

-EOF-
