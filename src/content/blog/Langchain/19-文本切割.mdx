---
title: æ–‡æœ¬åˆ‡å‰²
description: æ–‡æœ¬åˆ‡å‰²
pubDate: 2025-09-28
toc: true
ogImage: true
category: Langchain
---

**ä¸ºä»€ä¹ˆéœ€è¦åˆ‡å‰²ï¼Ÿ**

å›å¿†ä¸€ä¸‹ RAG çš„æµç¨‹ï¼š

1. ç”¨æˆ·æé—®
2. ä»çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³å†…å®¹
3. å°†æ£€ç´¢åˆ°çš„å†…å®¹å’Œç”¨æˆ·é—®é¢˜ä¸€èµ·äº¤ç»™æ¨¡å‹æ¨ç†

å¦‚æœæ–‡æ¡£ä¸åˆ‡å‰²ï¼Œæ£€ç´¢é˜¶æ®µå°±åªèƒ½ä»¥æ•´ç¯‡ä¸ºå•ä½ï¼Œé•¿æ–‡ä¼šè¶…å‡ºæ¨¡å‹çš„ Token é™åˆ¶ï¼Œæ— æ³•ä¸€æ¬¡æ€§é€è¿›æ¨¡å‹ã€‚

## å¿«é€Ÿä¸Šæ‰‹

**å¦‚ä½•åˆ‡å‰²ï¼Ÿ**

æœ€é€šç”¨çš„æ˜¯ä½¿ç”¨ `RecursiveCharacterTextSplitter` æ¥è¿›è¡Œåˆ‡å‰²ã€‚

```js
import { RecursiveCharacterTextSplitter } from 'langchain/text_splitter'
const splitter = new RecursiveCharacterTextSplitter({
  chunkSize: 64,
  chunkOverlap: 0,
})
```

- chunkSizeï¼šæ¯å—çš„æœ€å¤§é•¿åº¦
- chunkOverlapï¼šå—ä¹‹é—´çš„é‡å é•¿åº¦

åœ¨çº¿çš„ [å¯è§†åŒ–å·¥å…·](https://chunkviz.up.railway.app/)ï¼Œå¯ä»¥å¿«é€Ÿçœ‹åˆ°ä¸åŒ chunkSize å’Œ chunkOverlap çš„åˆ‡åˆ†æ•ˆæœã€‚åˆå­¦æ¨èè®¾ç½®ï¼šchunkSize = 1000ï¼ŒchunkOverlap = 200ï¼Œå†é€šè¿‡å·¥å…·è§‚å¯Ÿæ•ˆæœæ…¢æ…¢è°ƒã€‚

å¿«é€Ÿä¸Šæ‰‹ç¤ºä¾‹ï¼š

```js
import { RecursiveCharacterTextSplitter } from 'langchain/text_splitter'
import { TextLoader } from 'langchain/document_loaders/fs/text'

const loader = new TextLoader('data/kong.txt')

const docs = await loader.load()

const splitter = new RecursiveCharacterTextSplitter({
  chunkSize: 64,
  chunkOverlap: 10,
})

const result = await splitter.splitDocuments(docs)

console.log(result)
```

## å…¶å®ƒç±»å‹åˆ‡å‰²å™¨

ç°å®åœºæ™¯é‡Œï¼Œå¤„ç†çš„æ–‡æ¡£ç±»å‹äº”èŠ±å…«é—¨ï¼Œæ¯”å¦‚ï¼š

- ğŸ“„ Markdown æ•™æ¡ˆ
- ğŸŒ HTML é¡µé¢
- ğŸ§‘â€ğŸ’» JS/Python ä»£ç ç‰‡æ®µ
- ğŸ§¾ LaTeX æŠ¥å‘Š
- ğŸ“š è·¨è¯­è¨€ API æ–‡æ¡£â€¦â€¦

LangChain ä¸­æä¾›äº†ä¸åŒçš„åˆ‡å‰²å™¨

| Splitter åç§°                    | é€‚ç”¨æ–‡æ¡£ç±»å‹           | åˆ‡åˆ†ç­–ç•¥è¯´æ˜                     |
| -------------------------------- | ---------------------- | -------------------------------- |
| `RecursiveCharacterTextSplitter` | æ™®é€šæ–‡æœ¬ï¼ˆå°è¯´ã€è¯´æ˜ï¼‰ | é»˜è®¤æœ€å¸¸ç”¨ï¼ŒæŒ‰å­—ç¬¦å±‚çº§é€’è¿›åˆ‡åˆ†   |
| `MarkdownTextSplitter`           | Markdown æ–‡ä»¶          | æ ¹æ®æ ‡é¢˜å±‚çº§ï¼ˆ#ã€## ç­‰ï¼‰ç»“æ„æ¥åˆ‡ |
| `TokenTextSplitter`              | ç²¾ç¡®æ§åˆ¶ token æƒ…å†µ    | æŒ‰ token æ•°åˆ‡åˆ†ï¼Œä¸è€ƒè™‘è¯­ä¹‰      |
| `CharacterTextSplitter`          | éç»“æ„æ–‡æœ¬             | çº¯å­—ç¬¦åˆ‡ï¼Œç®€å•ç²—æš´               |

**åˆ‡å‰²Markdownç¤ºä¾‹**

```js
import { TextLoader } from 'langchain/document_loaders/fs/text'
import { MarkdownTextSplitter } from 'langchain/text_splitter'

const loader = new TextLoader('data/markdownè¯­æ³•.md')

const docs = await loader.load()

const splitter = new MarkdownTextSplitter({
  chunkSize: 300,
  chunkOverlap: 0,
})

const result = await splitter.splitDocuments(docs)

console.log(result)
```

**åˆ‡å‰²ä»£ç **

```js
import { RecursiveCharacterTextSplitter } from 'langchain/text_splitter'
import { TextLoader } from 'langchain/document_loaders/fs/text'

const loader = new TextLoader('data/test.js')

const docs = await loader.load()

const splitter = new RecursiveCharacterTextSplitter({
  chunkSize: 320,
  chunkOverlap: 0,
})

const result = await splitter.splitDocuments(docs)

console.log(result)
```

`RecursiveCharacterTextSplitter.fromLanguage("js", {...})`

- åˆ‡å‰²é€»è¾‘ï¼šåœ¨ `chunkSize` å’Œ `chunkOverlap` åŸºç¡€ä¸Šï¼Œä¼šæ ¹æ®æŒ‡å®šè¯­è¨€ï¼ˆè¿™é‡Œæ˜¯ `"js"`ï¼‰æ³¨å…¥ä¸“é—¨çš„åˆ†éš”ç¬¦è¡¨ã€‚

- JS ä¾‹å­ï¼š
  - ä¼˜å…ˆæŒ‰å‡½æ•°æˆ–ç±»å®šä¹‰ç­‰ç»“æ„åˆ†å‰²ï¼ˆ`function` / `class` ç­‰å…³é”®å­—å‘¨å›´ï¼‰

  - å†æŒ‰è¯­å¥ç»“æŸç¬¦ï¼ˆ`;`ï¼‰åˆ†å‰²

  - å†æŒ‰æ¢è¡Œç¬¦ã€ç©ºæ ¼ç­‰å…œåº•åˆ†å‰²

è¿™æ ·ä¼šå°½é‡é¿å…æŠŠä¸€è¡Œä»£ç åˆ‡æˆä¸¤åŠæˆ–ç ´åè¯­æ³•ç»“æ„ï¼Œåˆ©äºåç»­å¤§æ¨¡å‹ç†è§£ã€‚

```js
import { RecursiveCharacterTextSplitter } from 'langchain/text_splitter'
import { TextLoader } from 'langchain/document_loaders/fs/text'

const loader = new TextLoader('data/test.js')

const docs = await loader.load()

const splitter = RecursiveCharacterTextSplitter.fromLanguage('js', {
  chunkSize: 320,
  chunkOverlap: 0,
})

const result = await splitter.splitDocuments(docs)

console.log(result)
```

æ”¯æŒçš„ç¼–ç¨‹è¯­è¨€ï¼š

```js
import { SupportedTextSplitterLanguages } from 'langchain/text_splitter'
console.log(SupportedTextSplitterLanguages)
```

ä¹Ÿå¯ä»¥åœ¨ [è¿™é‡Œ](https://v03.api.js.langchain.com/classes/langchain.text_splitter.RecursiveCharacterTextSplitter.html#fromLanguage) çœ‹åˆ°ã€‚

**æŒ‰ç…§Tokenåˆ‡å‰²**

é€‚åˆç”¨åœ¨ token é¢„ç®—æ•æ„Ÿçš„åœºæ™¯ã€‚

```js
import { TokenTextSplitter } from 'langchain/text_splitter'

const text =
  'I stand before you today the representative of a family in grief, in a country in mourning before a world in shock.'

const splitter = new TokenTextSplitter({
  chunkSize: 10, // æ¯å—æœ€å¤š 10 ä¸ª token
  chunkOverlap: 0, // ä¸éœ€è¦é‡å 
})

const docs = await splitter.createDocuments([text])

console.log(docs)
```

`splitDocuments(docs)` â€”â€” ä¼  `Document` å¯¹è±¡

- è¾“å…¥ï¼šå¿…é¡»æ˜¯ LangChain çš„ `Document` å®ä¾‹æ•°ç»„ï¼ˆå½¢å¦‚ `{ pageContent, metadata }`ï¼‰ã€‚
- ä½œç”¨ï¼š
  - ä¼šä¿ç•™åŸæ¥çš„ `metadata`
  - åˆ‡å‰²å®Œçš„æ¯ä¸ª chunk ä¹Ÿä¼šå¸¦ä¸Šå¯¹åº”çš„ `metadata`
- å¸¸è§ç”¨æ³•ï¼šç”¨ loader åŠ è½½äº†æ–‡æ¡£ï¼ˆ`TextLoader`, `PDFLoader` ç­‰ï¼‰ï¼Œç›´æ¥æŠŠ `docs` äº¤ç»™å®ƒåˆ‡ã€‚

`createDocuments(texts, metadatas?)` â€”â€” ä¼ çº¯å­—ç¬¦ä¸²

- è¾“å…¥ï¼šçº¯æ–‡æœ¬æ•°ç»„ï¼ˆ`string[]`ï¼‰ï¼Œå¯é€‰ `metadata[]`
- ä½œç”¨ï¼š
  - å…ˆæŠŠå­—ç¬¦ä¸²å°è£…æˆ `Document` å¯¹è±¡
  - å†æŒ‰è§„åˆ™åˆ‡å‰²æˆå¤šä¸ªå°çš„ `Document`
- å¸¸è§ç”¨æ³•ï¼šä½ æ‰‹é‡Œæ²¡æœ‰ç°æˆçš„ `Document` å¯¹è±¡ï¼Œåªæœ‰ä¸€æ®µæ–‡æœ¬ï¼ˆæ¯”å¦‚ä»æ¥å£è¿”å›çš„å­—ç¬¦ä¸²ï¼‰ï¼Œéœ€è¦ç›´æ¥åˆ‡æˆ LangChain èƒ½ç”¨çš„ `Document[]`ã€‚

æ³¨æ„äº‹é¡¹ï¼š

- TokenTextSplitter ä¸ä¼šâ€œè€ƒè™‘è¯­è¨€ç»“æ„â€ï¼å®ƒåªæŒ‰ token æ•°ç¡¬åˆ‡ã€‚
- åˆ‡å‡ºæ¥çš„å—æœ‰å¯èƒ½æŠŠä¸€ä¸ªå¥å­ã€æ®µè½ã€ç”šè‡³ä¸€ä¸ªè¯ç»™åˆ‡æ–­ã€‚
- å®ƒé»˜è®¤ä½¿ç”¨çš„ tokenizer æ˜¯ Tiktokenï¼ˆé€‚é… OpenAI æ¨¡å‹ï¼‰ï¼Œå¦‚æœæ˜¯å…¶ä»–æ¨¡å‹ï¼Œå¯èƒ½ token æ•°ä¼šç•¥æœ‰å·®å¼‚ã€‚
